---
title: "Data_Analysis"
author: "Susanne_Rehorst"
date: "25-5-2022"
output: html_document
---

# Data Analysis
In the documents Data_Processing_Regulations.Rmd and Data_Processing_Metrics.Rmd, the data was cleaned and processed. In this markdown, analysis will be performed on this processed data.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load or install packages:
```{r}
library(dplyr)
library(stringr)
```

Set Working Directory
```{r}
setwd("~/Thesis")
```

## Load in the data
There are 3 data files used for this analysis. The first one is Descriptive_Data.RData, which contains the meta data for each document and descriptive statistics, like the amount of words and the readability of the document. The second one is Processed_Data.RData. This data file contains the tokenized regulations data, so that each row contains a token. The third data file that is loaded is Metrics_Data.RData. This file also contains tokenized data, but in this case it contains ESG metrics data.  
```{r}
load("Descriptive_Data.RData")
load("Processed_Data.RData")
load("Metrics_Data.RData")
```

# 1. Descriptive Analysis
The first part of the analysis looks at the descriptive statistics of the documents. 

## Quantity
Merge the words and non-words. Happens in case there are list that do not have a period at the end. 
```{r}
Descriptive_Data$totalwords <- rowSums(Descriptive_Data[,c(4,5)])
```

Sum totalwords and sentences if they apply to the same GroupID AND to the same DOC_TYPE and the same M type. In order to do this, a merge ID variable is created that uniquely identifies these groups. 
```{r}
# Create the merge ID variable
names <- c("GROUP_ID","DOC_TYPE","M")
Descriptive_Data[,names] <- lapply(Descriptive_Data[,names], as.character)
Descriptive_Data$MERGE_ID <- paste(Descriptive_Data$GROUP_TYPE, Descriptive_Data$GROUP_ID,Descriptive_Data$DOC_TYPE,Descriptive_Data$M)

# Set variables back to factor
names <- c("MERGE_ID","DOC_ID","GROUP_ID","GROUP_TYPE","DOC_TYPE","M","REGION")
Descriptive_Data[,names] <- lapply(Descriptive_Data[,names], factor)

# Get merged data by grouping on MERGE_ID
DOC_Quantity <- Descriptive_Data %>% group_by(MERGE_ID) %>%
  summarize(totalwords=sum(totalwords),
            sents=sum(sents))

# Split the MERGE_ID variable
DOC_Quantity[c('GROUP_TYPE', 'GROUP_ID', 'DOC_TYPE', 'M')] <- str_split_fixed(DOC_Quantity$MERGE_ID,' ',4)

# Create new merge variable
DOC_Quantity$MERGE_ID <- paste(DOC_Quantity$DOC_TYPE,DOC_Quantity$M)

# Set variables to factor
names <- c("MERGE_ID","GROUP_TYPE", "GROUP_ID","DOC_TYPE","M")
DOC_Quantity[,names] <- lapply(DOC_Quantity[,names], factor)

# Remove Group ID 42, 43, 44, as they do not contain ESG regulations (only key ESG metrics)
DOC_Quantity <- DOC_Quantity[DOC_Quantity$GROUP_ID!="42" & DOC_Quantity$GROUP_ID!="43" & DOC_Quantity$GROUP_ID!="44", ]
DOC_Quantity <- droplevels(DOC_Quantity)
```

Get the summary statistics for the aggregated data set.
```{r}
DOC_Stats <- DOC_Quantity %>%                              
  group_by(MERGE_ID) %>% 
  summarize(N=length(MERGE_ID),
            w_min = min(totalwords),
            w_q1 = quantile(totalwords, 0.25),
            w_median = median(totalwords),
            w_mean = mean(totalwords),
            w_q3 = quantile(totalwords, 0.75),
            w_max = max(totalwords),
            w_SD=sd(totalwords),
            s_min = min(sents),
            s_q1 = quantile(sents, 0.25),
            s_median = median(sents),
            s_mean = mean(sents),
            s_q3 = quantile(sents, 0.75),
            s_max = max(sents),
            s_SD=sd(sents))

DOC_Stats
```

Next, analysis is performed on group level. 
```{r}
# Group the data by Group_ID
Group_Quantity <- Descriptive_Data %>%
  group_by(GROUP_ID, GROUP_TYPE, M) %>%
  summarize(totalwords=sum(totalwords),
            sentences=sum(sents)) %>% ungroup()

# Remove Group ID 42, 43, 44, as they do not contain ESG regulations (only key ESG metrics)
Group_Quantity <- Group_Quantity[Group_Quantity$GROUP_ID!="42" & Group_Quantity$GROUP_ID!="43" & Group_Quantity$GROUP_ID!="44", ]
Group_Quantity <- droplevels(Group_Quantity)

# Get summary statistics 
Group_Stats <- Group_Quantity %>%                              
  group_by(GROUP_TYPE, M) %>% 
  summarize(
            w_min = min(totalwords),
            w_q1 = quantile(totalwords, 0.25),
            w_median = median(totalwords),
            w_mean = mean(totalwords),
            w_q3 = quantile(totalwords, 0.75),
            w_max = max(totalwords),
            w_SD=sd(totalwords),
            s_min = min(sentences),
            s_q1 = quantile(sentences, 0.25),
            s_median = median(sentences),
            s_mean = mean(sentences),
            s_q3 = quantile(sentences, 0.75),
            s_max = max(sentences),
            s_SD=sd(sentences))

Group_Stats
```

It is calculated what percentage of ESG group documents is made out of pure governance documents by combining information from DOC_Quantity and GROUP_Quantity. Also, merge those 2 documents with country to get more insights into countries that have a high amount of regulations and countries that have less. So all this information is summarized in the Results section. 
```{r}
# Create GROUP_ID, REGION identifier
Country_ID <- Descriptive_Data[,c(50,59)]
Country_ID <- distinct(Country_ID)

DOC_Quantity <- merge(DOC_Quantity, Country_ID, by.x = "GROUP_ID", by.y = "GROUP_ID", all.x = TRUE, all.y = FALSE)
Group_Quantity <- merge(Group_Quantity, Country_ID, by.x = "GROUP_ID", by.y = "GROUP_ID", all.x = TRUE, all.y = FALSE)
```

Test for significance. Also, log of totalwords and sentences is taken to create 2 new variables. In case the data is heavily skewed towards large numbers, these variables can be used. So, models with log transformed variables are included as a robustness check. 
```{r}
# Create log transformed variables
Group_Quantity$logwords <- log(Group_Quantity$totalwords)
Group_Quantity$logsents <- log(Group_Quantity$sentences)

# Significance between M and V (group level)
model1 <- lm(totalwords ~ M, data = Group_Quantity)
model2 <- lm(sentences ~ M, data = Group_Quantity)

# Log version
model3 <- lm(logwords ~ M, data = Group_Quantity)
model4 <- lm(logsents ~ M, data = Group_Quantity)

# Significance between M and V ESG regulations

# Create a sub sample
ESG_Group_Quantity <- Group_Quantity[Group_Quantity$GROUP_TYPE=="ESG", ]

# Significance between M and V (group level)
model5 <- lm(totalwords ~ M, data = ESG_Group_Quantity)
model6 <- lm(sentences ~ M, data = ESG_Group_Quantity)

# Log version
model7 <- lm(logwords ~ M, data = ESG_Group_Quantity)
model8 <- lm(logsents ~ M, data = ESG_Group_Quantity)

# Results
summary(model1)
summary(model2)
summary(model3)
summary(model4)
summary(model5)
summary(model6)
summary(model7)
summary(model8)
```

## Readability
This section analyzes the differences in readability score between groups. First, there are 7 out of of 70 cases removed where the amount of non-words > 0. This is an indication that the software was not able to correctly identify sentences and words. This is probably due to long lists where terms are summed up, but not separated by a punctuation mark. 
```{r}
Readability <- Descriptive_Data[Descriptive_Data$GROUP_ID!="2"& Descriptive_Data$GROUP_ID!="4"& Descriptive_Data$GROUP_ID!="17"& Descriptive_Data$GROUP_ID!="20"& Descriptive_Data$GROUP_ID!="21"& Descriptive_Data$GROUP_ID!="23"& Descriptive_Data$GROUP_ID!="31", ]
```

First, average readability between mandatory and voluntary documents is examined, irrespective of ESG type. 
```{r}
Readability_Total <- Readability %>%
  group_by(M) %>% 
  summarize(average_gl=mean(gl),
            average_ari=mean(ari),
            average_smog=mean(smog),
            average_cl=mean(cl),
            med_gl=median(gl),
            med_ari=median(ari),
            med_smog=median(smog),
            med_cl=median(cl))%>% ungroup()

Readability_Total
```

This difference is also tested for significance (and also with log).
```{r}
# Log transform variables
Readability$log_gl <- log(Readability$gl)
Readability$log_ari <- log(Readability$ari)
Readability$log_smog <- log(Readability$smog)
Readability$log_cl <- log(Readability$cl)

# Test for significance
model10 <- lm(gl~M, data = Readability)
model11 <- lm(log_gl~M, data = Readability)

model12 <- lm(ari~M, data = Readability)
model13 <- lm(log_ari~M, data = Readability)

model14 <- lm(smog~M, data = Readability)
model15 <- lm(log_smog~M, data = Readability)

model16 <- lm(cl~M, data = Readability)
model17 <- lm(log_cl~M, data = Readability)

summary(model10)
summary(model11)
summary(model12)
summary(model13)
summary(model14)
summary(model15)
summary(model16)
summary(model17)
```

While for quantity it is irrelevant to look at quantity differences at document level (as some documents only cover certain topics), it is relevant to do this for readability, as this measure is not influenced by the absolute quantity. 
```{r}
Readability_DOC <- Readability %>%
  group_by(DOC_TYPE, M) %>% 
  summarize(average_gl=mean(gl),
            average_ari=mean(ari),
            average_smog=mean(smog),
            average_cl=mean(cl),
            med_gl=median(gl),
            med_ari=median(ari),
            med_smog=median(smog),
            med_cl=median(cl))%>% ungroup()

Readability_DOC
```

Also, the significance between certain groups is examined. These are ESG(M)-ESG(V), ESG(M)-G(M), ESG(V)-E(V)
```{r}
# Log transform variables
Readability_DOC$log_gl <- log(Readability_DOC$gl)
Readability_DOC$log_ari <- log(Readability_DOC$ari)
Readability_DOC$log_smog <- log(Readability_DOC$smog)
Readability_DOC$log_cl <- log(Readability_DOC$cl)

# Create sub sample
ESG_Readability_DOC <- Readability_DOC[Readability_DOC$DOC_TYPE=="ESG", ]
M_Readability_DOC <- Readability_DOC[Readability_DOC$M=="1" & Readability_DOC$DOC_TYPE=="ESG" & Readability_DOC$DOC_TYPE=="G", ]
V_Readability_DOC <- Readability_DOC[Readability_DOC$M=="0" & Readability_DOC$DOC_TYPE=="ESG" & Readability_DOC$DOC_TYPE=="E", ]

# Test for significance - ESG M vs ESG V
model101 <- lm(gl~M, data = ESG_Readability_DOC)
model111 <- lm(log_gl~M, data = ESG_Readability_DOC)

model121 <- lm(ari~M, data = ESG_Readability_DOC)
model131 <- lm(log_ari~M, data = ESG_Readability_DOC)

model141 <- lm(smog~M, data = ESG_Readability_DOC)
model151 <- lm(log_smog~M, data = ESG_Readability_DOC)

model161 <- lm(cl~M, data = ESG_Readability_DOC)
model171 <- lm(log_cl~M, data = ESG_Readability_DOC)

summary(model101)
summary(model111)
summary(model121)
summary(model131)
summary(model141)
summary(model151)
summary(model161)
summary(model171)

# Test for significance - ESG M vs G M
model102 <- lm(gl~DOC_TYPE, data = M_Readability_DOC)
model112 <- lm(log_gl~DOC_TYPE, data = M_Readability_DOC)

model122 <- lm(ari~DOC_TYPE, data = M_Readability_DOC)
model132 <- lm(log_ari~DOC_TYPE, data = M_Readability_DOC)

model142 <- lm(smog~DOC_TYPE, data = M_Readability_DOC)
model152 <- lm(log_smog~DOC_TYPE, data = M_Readability_DOC)

model162 <- lm(cl~DOC_TYPE, data = M_Readability_DOC)
model172 <- lm(log_cl~DOC_TYPE, data = M_Readability_DOC)

summary(model102)
summary(model112)
summary(model122)
summary(model132)
summary(model142)
summary(model152)
summary(model162)
summary(model172)


# Test for significance - ESG V vs E V
model103 <- lm(gl~DOC_TYPE, data = V_Readability_DOC)
model113 <- lm(log_gl~DOC_TYPE, data = V_Readability_DOC)

model123 <- lm(ari~DOC_TYPE, data = V_Readability_DOC)
model133 <- lm(log_ari~DOC_TYPE, data = V_Readability_DOC)

model143 <- lm(smog~DOC_TYPE, data = V_Readability_DOC)
model153 <- lm(log_smog~DOC_TYPE, data = V_Readability_DOC)

model163 <- lm(cl~DOC_TYPE, data = V_Readability_DOC)
model173 <- lm(log_cl~DOC_TYPE, data = V_Readability_DOC)

summary(model103)
summary(model113)
summary(model123)
summary(model133)
summary(model143)
summary(model153)
summary(model163)
summary(model173)
```

Subsequently, the average and median readability scores are calculated for each group. 
```{r}
# Group the data by Group_ID
Group_Readability <- Readability %>%
  group_by(GROUP_ID, GROUP_TYPE, M) %>%
  summarize(average_gl=mean(gl),
            average_ari=mean(ari),
            average_smog=mean(smog),
            average_cl=mean(cl),
            med_gl=median(gl),
            med_ari=median(ari),
            med_smog=median(smog),
            med_cl=median(cl))%>% ungroup()

# Remove Group ID 42, 43, 44, as they do not contain ESG regulations (only key ESG metrics)
Group_Readability <- Group_Readability[Group_Readability$GROUP_ID!="42" & Group_Readability$GROUP_ID!="43" & Group_Readability$GROUP_ID!="44", ]
Group_Readability <- droplevels(Group_Readability)

# Get summary statistics 
Group_R_Stats <- Group_Readability %>%                              
  group_by(GROUP_TYPE, M) %>% 
  summarize(average_gl=mean(average_gl),
            average_ari=mean(average_ari),
            average_smog=mean(average_smog),
            average_cl=mean(average_cl),
            med_gl=median(med_gl),
            med_ari=median(med_ari),
            med_smog=median(med_smog),
            med_cl=median(med_cl)) %>% ungroup()

Group_R_Stats
```

Attach Region to the group and doc level analysis, to look for interesting patterns. 
```{r}
Readability_DOC <- merge(Readability_DOC, Country_ID, by.x = "GROUP_ID", by.y = "GROUP_ID", all.x = TRUE, all.y = FALSE)
Group_Readability <- merge(Group_Readability, Country_ID, by.x = "GROUP_ID", by.y = "GROUP_ID", all.x = TRUE, all.y = FALSE)
```

Lastly, the significance is tested within the group readability. 
```{r}
# Log transform variables
Group_Readability$log_gl <- log(Group_Readability$gl)
Group_Readability$log_ari <- log(Group_Readability$ari)
Group_Readability$log_smog <- log(Group_Readability$smog)
Group_Readability$log_cl <- log(Group_Readability$cl)

# Test for significance - M vs V
model1011 <- lm(gl~M, data = Group_Readability)
model1111 <- lm(log_gl~M, data = Group_Readability)

model1211 <- lm(ari~M, data = Group_Readability)
model1311 <- lm(log_ari~M, data = Group_Readability)

model1411 <- lm(smog~M, data = Group_Readability)
model1511 <- lm(log_smog~M, data = Group_Readability)

model1611 <- lm(cl~M, data = Group_Readability)
model1711 <- lm(log_cl~M, data = Group_Readability)

summary(model1011)
summary(model1111)
summary(model1211)
summary(model1311)
summary(model1411)
summary(model1511)
summary(model1611)
summary(model1711)

# Create sub sample
ESG_Group_Readability <- Group_Readability[Group_Readability$GROUP_TYPE=="ESG", ]
M_Group_Readability <- Group_Readability[Group_Readability$M=="1", ]
V_Group_Readability <- Group_Readability[Group_Readability$M=="0", ]

# Test for significance - ESG M vs ESG V
modelx101 <- lm(gl~M, data = ESG_Group_Readability)
modelx111 <- lm(log_gl~M, data = ESG_Group_Readability)

modelx121 <- lm(ari~M, data = ESG_Group_Readability)
modelx131 <- lm(log_ari~M, data = ESG_Group_Readability)

modelx141 <- lm(smog~M, data = ESG_Group_Readability)
modelx151 <- lm(log_smog~M, data = ESG_Group_Readability)

modelx161 <- lm(cl~M, data = ESG_Group_Readability)
modelx171 <- lm(log_cl~M, data = ESG_Group_Readability)

summary(modelx101)
summary(modelx111)
summary(modelx121)
summary(modelx131)
summary(modelx141)
summary(modelx151)
summary(modelx161)
summary(modelx171)

# Test for significance - ESG M vs G M
modelx102 <- lm(gl~GROUP_TYPE, data = M_Group_Readability)
modelx112 <- lm(log_gl~GROUP_TYPE, data = M_Group_Readability)

modelx122 <- lm(ari~GROUP_TYPE, data = M_Group_Readability)
modelx132 <- lm(log_ari~GROUP_TYPE, data = M_Group_Readability)

modelx142 <- lm(smog~GROUP_TYPE, data = M_Group_Readability)
modelx152 <- lm(log_smog~GROUP_TYPE, data = M_Group_Readability)

modelx162 <- lm(cl~GROUP_TYPE, data = M_Group_Readability)
modelx172 <- lm(log_cl~GROUP_TYPE, data = M_Group_Readability)

summary(modelx102)
summary(modelx112)
summary(modelx122)
summary(modelx132)
summary(modelx142)
summary(modelx152)
summary(modelx162)
summary(modelx172)


# Test for significance - ESG V vs E V
modelx103 <- lm(gl~GROUP_TYPE, data = V_Group_Readability)
modelx113 <- lm(log_gl~GROUP_TYPE, data = V_Group_Readability)

modelx123 <- lm(ari~GROUP_TYPE, data = V_Group_Readability)
modelx133 <- lm(log_ari~GROUP_TYPE, data = V_Group_Readability)

modelx143 <- lm(smog~GROUP_TYPE, data = V_Group_Readability)
modelx153 <- lm(log_smog~GROUP_TYPE, data = V_Group_Readability)

modelx163 <- lm(cl~GROUP_TYPE, data = V_Group_Readability)
modelx173 <- lm(log_cl~GROUP_TYPE, data = V_Group_Readability)

summary(modelx103)
summary(modelx113)
summary(modelx123)
summary(modelx133)
summary(modelx143)
summary(modelx153)
summary(modelx163)
summary(modelx173)
```


## Restrictiveness
First, the total number of restrictive words is divided by the total number of words. This prevents a bias where large texts already contain a larger portion of restrictive words. 
```{r}

```






















#2. Similarity Analysis
The second part of the analysis focuses on the similarity between documents. 

## Merging on group level
Merge on group level.
```{r}

```

## Document term matrix
```{r}

```

## Local weighting function
```{r}

```

## Create separate corpera before applying global weighting function
There is a total of 8 different corpera calculated. M-ESG; M-ESG+ESGtopics; M-G; M-G+Gtopics; V-ESG; V-E; V-ESG+ESGtopics; V-E+Etopics
```{r}

```

## Global weighting function
```{r}

```

## Final weight and normalization
```{r}

```

## Cosine similarity matrix
```{r}

```

## Calculating Difference-in-Means and test for significance (within groups and compared to ESG doc)
```{r}

```

## Regression (optional)
```{r}

```

## Robustness check
```{r}

```






#3. ESG keywords analysis

## Select ESG key topics
Use the ESG Metrics documents to define the key words for every ESG metric. This is done by looking at both 1-gram, 2-gram and 3-gram expression. Importance of a ESG key metric is determined by looking at the key expressions with the highest TF. 
```{r}

```

## Calculate total global weight and total local weight for each ESG metric within each regulatory document group
```{r}

```

## Match with meta data and visualize the results
```{r}

```

## Calculate the Difference in average weight for each ESG metric between different document groups
```{r}

```

## Regression on global weight
```{r}

```

## Regression on local weight
```{r}

```

## Robustness check
```{r}

```


# 4. Optional: Visualization (network or wordcloud etc.)
```{r}

```

